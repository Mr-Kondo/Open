{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MS-H2020/Open/blob/main/Anomaly_Sound_Detection_MobileNet_one_hold.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P_hsgoGPLdjq"
   },
   "source": [
    "# [機械稼働音の異常検知 （EDA）](https://signate.jp/competitions/358)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 [音声ファイル特徴量変換（その5）メルスペクトログラム(TensorFlow)](https://work-in-progress.hatenablog.com/entry/2020/03/08/095914)  \n",
    "2 [Tensorflow, 簡単な音声認識: キーワードの認識](https://www.tensorflow.org/tutorials/audio/simple_audio?hl=ja)  \n",
    "3 [「ToyADMOS:異常音検知」：AutoEncoder](https://note.com/toshi_sugi/n/nc4a5b9c4d6cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "uBH1mElMFuKX"
   },
   "outputs": [],
   "source": [
    "## Import modules\n",
    "import gc\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "flag = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの生のWAVオーディオファイルをオーディオテンソルに前処理する関数を定義\n",
    "# normalized to the [-1.0, 1.0] range\n",
    "def decode_audio(audio_binary):\n",
    "  audio, _ = tf.audio.decode_wav(contents=audio_binary)\n",
    "  return tf.squeeze(audio, axis=-1) # モノラル信号のため、チャンネル軸を除去\n",
    "def get_waveform(file_path):\n",
    "  audio_binary = tf.io.read_file(file_path)\n",
    "  waveform = decode_audio(audio_binary)\n",
    "  return waveform\n",
    "\n",
    "def get_fft(waveform):\n",
    "  # 波形をフーリエ変換\n",
    "  # 周波数はlog10スケールに変換\n",
    "  waveform = tf.complex(waveform, 0.0)\n",
    "  fft = tf.signal.fft(waveform)\n",
    "  fft = tf.abs(fft)\n",
    "  # Convert the frequencies to log scale and transpose\n",
    "  fft_log_spec = tf.experimental.numpy.log10((fft + 2.2204460492503131e-16) / 2.2204460492503131e-16)\n",
    "  fft_log_spec = fft_log_spec[0:len(fft)//2]\n",
    "  return fft_log_spec\n",
    "\n",
    "def get_stft_spectrogram(waveform):\n",
    "  # Convert the waveform to a spectrogram via a STFT.\n",
    "    # Input: A Tensor of [batch_size, num_samples]\n",
    "    # mono PCM samples in the range [-1, 1].\n",
    "  stft = tf.signal.stft(waveform,\n",
    "                        frame_length=255,\n",
    "                        frame_step=128)\n",
    "\n",
    "  # Obtain the Power of the STFT.\n",
    "  spectrogram = tf.square(tf.abs(stft))\n",
    "\n",
    "  # Add a `channels` dimension, so that the spectrogram can be used\n",
    "  # as image-like input data with convolution layers (wh\n",
    "  return spectrogram\n",
    "\n",
    "def get_mel_spectrogram(stft_spectrogram):\n",
    "    # STFT-bin\n",
    "    n_stft_bin = stft_spectrogram.shape[-1]          # --> 257 (= FFT size / 2 + 1)\n",
    "\n",
    "    linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n",
    "        num_mel_bins=128,\n",
    "        num_spectrogram_bins=n_stft_bin,\n",
    "        sample_rate=16000,\n",
    "        lower_edge_hertz=0.0,\n",
    "        upper_edge_hertz=8000.0\n",
    "    )\n",
    "    # --> shape=(257, 128) = (FFT size / 2 + 1, num of mel bins)\n",
    "    mel_spectrogram = tf.tensordot(\n",
    "        stft_spectrogram,             # (1, 98?, 257)\n",
    "        linear_to_mel_weight_matrix,  # (257, 128)\n",
    "        1)\n",
    "    \n",
    "    #log_mel_spectrogram = tf.math.log(mel_spectrogram + 1e-6)\n",
    "\n",
    "    return mel_spectrogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrogram(spectrogram, ax, sr=16000, frame_step=128):\n",
    "  tf.experimental.numpy.experimental_enable_numpy_behavior()\n",
    "  if len(spectrogram.shape) > 2:\n",
    "    assert len(spectrogram.shape) == 3\n",
    "    spectrogram = np.squeeze(spectrogram, axis=-1)\n",
    "  # Convert the frequencies to log scale and transpose, so that the time is\n",
    "  # represented on the x-axis (columns).\n",
    "  # Add an epsilon to avoid taking a log of zero.\n",
    "  log_spec = np.log10(spectrogram.T + np.finfo(float).eps)\n",
    "  height = log_spec.shape[0]\n",
    "  width = log_spec.shape[1]\n",
    "  time_axis = np.arange(width) * (frame_step / sr)   # 0 ~ width-1 (時間フレームのインデックス)\n",
    "  freq_axis = np.linspace(0, sr/2, height)  # 0 ~ height-1 (周波数ビンのインデックス)\n",
    "  \n",
    "  ax.pcolormesh(time_axis, freq_axis, log_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Notmal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total examples: 300\n",
      "Example file tensor: ../01_input/wav/train_normal/dummy/000.wav\n"
     ]
    }
   ],
   "source": [
    "# オーディオクリップをfilenamesというリストに抽出します\n",
    "filenames = glob.glob('../01_input/wav/train_normal/dummy/*.wav')\n",
    "num_samples = len(filenames)\n",
    "filenames.sort()\n",
    "print('Number of total examples:', num_samples)\n",
    "print('Example file tensor:', filenames[0])\n",
    "\n",
    "flag = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_wav_file(i):\n",
    "    if flag == False:\n",
    "        print(\"Please run the above cell.\")\n",
    "        return\n",
    "    \n",
    "    from IPython import display\n",
    "    train_file = tf.io.read_file(filenames[i])\n",
    "    train_audio, sampling_rate = tf.audio.decode_wav(contents=train_file)\n",
    "    \n",
    "    # Audio Setting\n",
    "    Data_num = train_audio.shape[0]\n",
    "    Sampling_freq = sampling_rate.numpy()\n",
    "    time_length = Data_num / Sampling_freq \n",
    "\n",
    "    print(\"File: \", filenames[i])\n",
    "    print(\"Data数: \", Data_num)\n",
    "    print(\"サンプリング周波数[Hz]: \", Sampling_freq)\n",
    "    print(\"時間窓長[sec]: \", time_length)\n",
    "    print(\"分析周波数レンジ[Hz]: \", Sampling_freq / 2,'\\n')\n",
    "    \n",
    "    waveform = get_waveform(filenames[i])\n",
    "    fft = get_fft(waveform)\n",
    "    stft_spectrogram =get_stft_spectrogram(waveform)\n",
    "    mel_spectrogram = get_mel_spectrogram(stft_spectrogram)\n",
    "        \n",
    "    # 時間波形と周波数波形をプロット\n",
    "    timescale = np.arange(Data_num) #len(waveform)\n",
    "    timescale = timescale/Sampling_freq\n",
    "    freq = np.arange(Data_num//2) * Sampling_freq / Data_num \n",
    "    \n",
    "    display.display(display.Audio(waveform, rate=Sampling_freq))\n",
    "\n",
    "    fig, axes = plt.subplots(4, figsize=(12, 25))\n",
    "    \n",
    "    axes[0].plot(timescale, waveform.numpy())\n",
    "    axes[0].set_title('Waveform')\n",
    "    axes[0].set_xlim([0, Data_num/Sampling_freq]) # [0, Data_num]\n",
    "    axes[0].set_xlabel(\"time[sec]\")\n",
    "    axes[0].grid()\n",
    "    \n",
    "    axes[1].plot(freq/1000, fft) \n",
    "    axes[1].set_title('FFT Specto')\n",
    "    axes[1].set_xlabel(\"frequency[kHz]\")\n",
    "    axes[1].set_ylabel(\"[dB]\")\n",
    "    axes[1].grid()\n",
    "    \n",
    "    axes[2].set_title('STFT Spectrogram')\n",
    "    plot_spectrogram(stft_spectrogram, axes[2])\n",
    "    axes[2].set_xlabel(\"time[sec]\")\n",
    "    axes[2].set_ylabel(\"frequency\")\n",
    "    axes[2].grid()\n",
    "    \n",
    "    axes[3].set_title('Mel Spectrogram')\n",
    "    plot_spectrogram(mel_spectrogram, axes[3])\n",
    "    axes[3].set_xlabel(\"time[sec]\")\n",
    "    axes[3].set_ylabel(\"frequency\")\n",
    "    axes[3].grid()\n",
    "    \n",
    "    plt.show()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da8b662c78674dc7930091ffc983b475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='wav file:', max=300), Output()), _dom_classes=('widget-i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.show_wav_file(i)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from  ipywidgets import interact\n",
    "import ipywidgets as widgets\n",
    "\n",
    "slider = widgets.IntSlider(\n",
    "    value=0,                        # 初めの値\n",
    "    min=0,                          # 最小値\n",
    "    max=len(filenames)-1,             # 最大値\n",
    "    step=1,                         # ステップ数\n",
    "    description='wav file:',   # スライダーの名前\n",
    "    orientation='horizontal'        # 位置、verticalなら縦になる\n",
    ")\n",
    "\n",
    "interact(show_wav_file, i=slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valid Notmal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total examples: 150\n",
      "Example file tensor: ../01_input/wav/valid_normal/dummy/000.wav\n"
     ]
    }
   ],
   "source": [
    "# オーディオクリップをfilenamesというリストに抽出します\n",
    "filenames = glob.glob('../01_input/wav/valid_normal/dummy/*.wav')\n",
    "num_samples = len(filenames)\n",
    "filenames.sort()\n",
    "print('Number of total examples:', num_samples)\n",
    "print('Example file tensor:', filenames[0])\n",
    "\n",
    "flag = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_wav_file(i):\n",
    "    if flag == False:\n",
    "        print(\"Please run the above cell.\")\n",
    "        return\n",
    "    \n",
    "    from IPython import display\n",
    "    valid_normal_file = tf.io.read_file(filenames[i])\n",
    "    valid_normal_audio, sampling_rate = tf.audio.decode_wav(contents=valid_normal_file)\n",
    "    \n",
    "    # Audio Setting\n",
    "    Data_num = valid_normal_audio.shape[0]\n",
    "    Sampling_freq = sampling_rate.numpy()\n",
    "    time_length = Data_num / Sampling_freq \n",
    "\n",
    "    print(\"File: \", filenames[i])\n",
    "    print(\"Data数: \", Data_num)\n",
    "    print(\"サンプリング周波数[Hz]: \", Sampling_freq)\n",
    "    print(\"時間窓長[sec]: \", time_length)\n",
    "    print(\"分析周波数レンジ[Hz]: \", Sampling_freq / 2,'\\n')\n",
    "    \n",
    "    waveform = get_waveform(filenames[i])\n",
    "    fft = get_fft(waveform)\n",
    "    stft_spectrogram =get_stft_spectrogram(waveform)\n",
    "    mel_spectrogram = get_mel_spectrogram(stft_spectrogram)\n",
    "        \n",
    "    # 時間波形と周波数波形をプロット\n",
    "    timescale = np.arange(Data_num) #len(waveform)\n",
    "    timescale = timescale/Sampling_freq\n",
    "    freq = np.arange(Data_num//2) * Sampling_freq / Data_num \n",
    "\n",
    "    display.display(display.Audio(waveform, rate=Sampling_freq))\n",
    "    \n",
    "    fig, axes = plt.subplots(4, figsize=(12, 25))\n",
    "    \n",
    "    axes[0].plot(timescale, waveform.numpy())\n",
    "    axes[0].set_title('Waveform')\n",
    "    axes[0].set_xlim([0, Data_num/Sampling_freq]) # [0, Data_num]\n",
    "    axes[0].set_xlabel(\"time[sec]\")\n",
    "    axes[0].grid()\n",
    "    \n",
    "    axes[1].plot(freq/1000, fft) \n",
    "    axes[1].set_title('FFT Specto')\n",
    "    axes[1].set_xlabel(\"frequency[kHz]\")\n",
    "    axes[1].set_ylabel(\"[dB]\")\n",
    "    axes[1].grid()\n",
    "    \n",
    "    axes[2].set_title('STFT Spectrogram')\n",
    "    plot_spectrogram(stft_spectrogram, axes[2])\n",
    "    axes[2].set_xlabel(\"time[sec]\")\n",
    "    axes[2].set_ylabel(\"frequency\")\n",
    "    axes[2].grid()\n",
    "    \n",
    "    axes[3].set_title('lMel Spectrogram')\n",
    "    #axes[3].plot(mel_spectrogram) \n",
    "    plot_spectrogram(mel_spectrogram, axes[3])\n",
    "    axes[3].set_xlabel(\"time[sec]\")\n",
    "    axes[3].set_ylabel(\"frequency\")\n",
    "    axes[3].grid()\n",
    "    \n",
    "    plt.show()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80ff33208aa947ab9a3ea0be0a7b5768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='wav file:', max=150), Output()), _dom_classes=('widget-i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.show_wav_file(i)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slider = widgets.IntSlider(\n",
    "    value=0,                        # 初めの値\n",
    "    min=0,                          # 最小値\n",
    "    max=len(filenames)-1,           # 最大値\n",
    "    step=1,                         # ステップ数\n",
    "    description='wav file:',   # スライダーの名前\n",
    "    orientation='horizontal'        # 位置、verticalなら縦になる\n",
    ")\n",
    "\n",
    "interact(show_wav_file, i=slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valid Anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total examples: 50\n",
      "Example file tensor: ../01_input/wav/valid_anomaly/dummy/000.wav\n"
     ]
    }
   ],
   "source": [
    "# オーディオクリップをfilenamesというリストに抽出します\n",
    "filenames = glob.glob('../01_input/wav/valid_anomaly/dummy/*.wav')\n",
    "num_samples = len(filenames)\n",
    "filenames.sort()\n",
    "print('Number of total examples:', num_samples)\n",
    "print('Example file tensor:', filenames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_wav_file(i):\n",
    "    if flag == False:\n",
    "        print(\"Please run the above cell.\")\n",
    "        return\n",
    "    \n",
    "    from IPython import display\n",
    "    valid_anomaly_file = tf.io.read_file(filenames[i])\n",
    "    valid_anomaly_audio, sampling_rate = tf.audio.decode_wav(contents=valid_anomaly_file)\n",
    "    \n",
    "    # Audio Setting\n",
    "    Data_num = valid_anomaly_audio.shape[0]\n",
    "    Sampling_freq = sampling_rate.numpy()\n",
    "    time_length = Data_num / Sampling_freq \n",
    "\n",
    "    print(\"File: \", filenames[i])\n",
    "    print(\"Data数: \", Data_num)\n",
    "    print(\"サンプリング周波数[Hz]: \", Sampling_freq)\n",
    "    print(\"時間窓長[sec]: \", time_length)\n",
    "    print(\"分析周波数レンジ[Hz]: \", Sampling_freq / 2,'\\n')\n",
    "    \n",
    "    waveform = get_waveform(filenames[i])\n",
    "    fft = get_fft(waveform)\n",
    "    stft_spectrogram =get_stft_spectrogram(waveform)\n",
    "    mel_spectrogram = get_mel_spectrogram(stft_spectrogram)\n",
    "        \n",
    "    # 時間波形と周波数波形をプロット\n",
    "    timescale = np.arange(Data_num) #len(waveform)\n",
    "    timescale = timescale/Sampling_freq\n",
    "    freq = np.arange(Data_num//2) * Sampling_freq / Data_num \n",
    "\n",
    "    display.display(display.Audio(waveform, rate=Sampling_freq))\n",
    "    \n",
    "    fig, axes = plt.subplots(4, figsize=(12, 25))\n",
    "    \n",
    "    axes[0].plot(timescale, waveform.numpy())\n",
    "    axes[0].set_title('Waveform')\n",
    "    axes[0].set_xlim([0, Data_num/Sampling_freq]) # [0, Data_num]\n",
    "    axes[0].set_xlabel(\"time[sec]\")\n",
    "    axes[0].grid()\n",
    "    \n",
    "    axes[1].plot(freq/1000, fft) \n",
    "    axes[1].set_title('FFT Specto')\n",
    "    axes[1].set_xlabel(\"frequency[kHz]\")\n",
    "    axes[1].set_ylabel(\"[dB]\")\n",
    "    axes[1].grid()\n",
    "    \n",
    "    axes[2].set_title('STFT Spectrogram')\n",
    "    plot_spectrogram(stft_spectrogram, axes[2])\n",
    "    axes[2].set_xlabel(\"time[sec]\")\n",
    "    axes[2].set_ylabel(\"frequency\")\n",
    "    axes[2].grid()\n",
    "    \n",
    "    axes[3].set_title('lMel Spectrogram')\n",
    "    #axes[3].plot(mel_spectrogram) \n",
    "    plot_spectrogram(mel_spectrogram, axes[3])\n",
    "    axes[3].set_xlabel(\"time[sec]\")\n",
    "    axes[3].set_ylabel(\"frequency\")\n",
    "    axes[3].grid()\n",
    "    \n",
    "    plt.show()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74f47ea8159844609a7d8eae922b8032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='wav file:', max=49), Output()), _dom_classes=('widget-in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.show_wav_file(i)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slider = widgets.IntSlider(\n",
    "    value=0,                        # 初めの値\n",
    "    min=0,                          # 最小値\n",
    "    max=len(filenames)-1,             # 最大値\n",
    "    step=1,                         # ステップ数\n",
    "    description='wav file:',   # スライダーの名前\n",
    "    orientation='horizontal'        # 位置、verticalなら縦になる\n",
    ")\n",
    "\n",
    "interact(show_wav_file, i=slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total examples: 200\n",
      "Example file tensor: ../01_input/wav/test/dummy/000.wav\n"
     ]
    }
   ],
   "source": [
    "# オーディオクリップをfilenamesというリストに抽出します\n",
    "filenames = glob.glob('../01_input/wav/test/dummy/*.wav')\n",
    "num_samples = len(filenames)\n",
    "filenames.sort()\n",
    "print('Number of total examples:', num_samples)\n",
    "print('Example file tensor:', filenames[0])\n",
    "\n",
    "flag = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_wav_file(i):\n",
    "    if flag == False:\n",
    "        print(\"Please run the above cell.\")\n",
    "        return\n",
    "    \n",
    "    from IPython import display\n",
    "    valid_anomaly_file = tf.io.read_file(filenames[i])\n",
    "    valid_anomaly_audio, sampling_rate = tf.audio.decode_wav(contents=valid_anomaly_file)\n",
    "    \n",
    "    # Audio Setting\n",
    "    Data_num = valid_anomaly_audio.shape[0]\n",
    "    Sampling_freq = sampling_rate.numpy()\n",
    "    time_length = Data_num / Sampling_freq \n",
    "\n",
    "    print(\"File: \", filenames[i])\n",
    "    print(\"Data数: \", Data_num)\n",
    "    print(\"サンプリング周波数[Hz]: \", Sampling_freq)\n",
    "    print(\"時間窓長[sec]: \", time_length)\n",
    "    print(\"分析周波数レンジ[Hz]: \", Sampling_freq / 2,'\\n')\n",
    "    \n",
    "    waveform = get_waveform(filenames[i])\n",
    "    fft = get_fft(waveform)\n",
    "    stft_spectrogram =get_stft_spectrogram(waveform)\n",
    "    mel_spectrogram = get_mel_spectrogram(stft_spectrogram)\n",
    "        \n",
    "    # 時間波形と周波数波形をプロット\n",
    "    timescale = np.arange(Data_num) #len(waveform)\n",
    "    timescale = timescale/Sampling_freq\n",
    "    freq = np.arange(Data_num//2) * Sampling_freq / Data_num \n",
    "\n",
    "    display.display(display.Audio(waveform, rate=Sampling_freq))\n",
    "    \n",
    "    fig, axes = plt.subplots(4, figsize=(12, 25))\n",
    "    \n",
    "    axes[0].plot(timescale, waveform.numpy())\n",
    "    axes[0].set_title('Waveform')\n",
    "    axes[0].set_xlim([0, Data_num/Sampling_freq]) # [0, Data_num]\n",
    "    axes[0].set_xlabel(\"time[sec]\")\n",
    "    axes[0].grid()\n",
    "    \n",
    "    axes[1].plot(freq/1000, fft) \n",
    "    axes[1].set_title('FFT Specto')\n",
    "    axes[1].set_xlabel(\"frequency[kHz]\")\n",
    "    axes[1].set_ylabel(\"[dB]\")\n",
    "    axes[1].grid()\n",
    "    \n",
    "    axes[2].set_title('STFT Spectrogram')\n",
    "    plot_spectrogram(stft_spectrogram, axes[2])\n",
    "    axes[2].set_xlabel(\"time[sec]\")\n",
    "    axes[2].set_ylabel(\"frequency\")\n",
    "    axes[2].grid()\n",
    "    \n",
    "    axes[3].set_title('lMel Spectrogram')\n",
    "    plot_spectrogram(mel_spectrogram, axes[3])\n",
    "    axes[3].set_xlabel(\"time[sec]\")\n",
    "    axes[3].set_ylabel(\"frequency\")\n",
    "    axes[3].grid()\n",
    "    \n",
    "    plt.show()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72abba756f1442298ef0b396da005438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='wav file:', max=199), Output()), _dom_classes=('widget-i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.show_wav_file(i)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slider = widgets.IntSlider(\n",
    "    value=0,                        # 初めの値\n",
    "    min=0,                          # 最小値\n",
    "    max=len(filenames)-1,             # 最大値\n",
    "    step=1,                         # ステップ数\n",
    "    description='wav file:',   # スライダーの名前\n",
    "    orientation='horizontal'        # 位置、verticalなら縦になる\n",
    ")\n",
    "\n",
    "interact(show_wav_file, i=slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = False"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP/bJX31VNCwYIO9lDB1ZQH",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf-metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
